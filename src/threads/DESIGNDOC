            +-------------------+
            |       OS 211      |
            |  TASK 1: THREADS  |
            |  DESIGN DOCUMENT  |
            +-------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Milan Misak <mm5510@imperial.ac.uk>
Jack Bracewell <jb2910@doc.ic.ac.uk>
Craig Ellis <ce710@doc.ic.ac.uk>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int64_t ticks_when_awake;          /* Timer ticks count when awakened. */
    struct list_elem sleepelem;        /* List element for sleeping list. */
    struct semaphore sleepsema;        /* Semaphore to make a thread sleep
                                          and wake it up. */
    struct semaphore priority_sema;    /* Semaphore to control access to 
                                          donated priorities */


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

All that timer_sleep() does is make sure that interrupts are enabled, then
call thread_sleep(). The value passed to thread_sleep() specifies on (or
after) which tick the timer can be woken up. (The given value will be checked
before schedule() chooses another thread to run).

Similarly, the timer interrupt handler simply increments 'ticks', then calls
thread_tick(). This will ncrement the appropriate one of 'idle_ticks',
'user_ticks', or 'kernel_ticks', as before. The only change we have made is
that it will also implement the BSD scheduler correctly.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Since the spec calls for a sleep function which 'need not wake up [the thread]
after exactly x ticks', we decided that rather than check the sleeping threads
on every tick, to see if they should be woken up, we only check them when
schedule() is called. (The only change made to the calling of the interrupt
handler is the implementation of the BSD scheduler).


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

When multiple threads call timer_sleep() at the same time, there is a
possiblility that they will both insert themselves into the same place in the
list of seeping threads. This could cause them to overwrite each other, or the
ordering of the list. It is easily avoided by locking the shared resource (the
list of sleepng threads) with a semaphore.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Had we woken threads up in timer_ticks(), rather than in schedule(), the list
of sleeping threads could encounter the same problems as if two calls to
timer_sleep() were trying to access it simultaneously (the previous question).
However, we have avoided this by simply not touching the list of sleeping
threads in the timer interrupt handler.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design to try to minimise the amont of time in interrupts. For
example, we only wake sleeping threads when schedule() is called, and don't
bother to check them on every tick.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int self_set_priority;             /* Priority that has not been set
                                          via donation. */
    struct lock *blocking_lock;        /* Lock causing the thread to block. */
    struct list donated_priorities;    /* List of locks and donated priorities
                                          for them. */

Added to struct semaphore_elem:

    struct thread *thread;             /* The thread waiting on the
                                          condition */

New struct:

struct donated_priority
  {
    struct lock *blocking_lock;     /* The lock causing priority to be 
                                       donated. */
    int priority;                   /* The priority donated. */
    struct list_elem priority_elem; /* Element in a thread's donated
                                       priority list.*/
  };


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

The tracking system for priority donation only allows for threads to be
tracked that need to be donated to, there is no way of knowing where
a donation has come from from the receiving thread's point of view,
because it does not need to know.

When trying to track down threads a thread needs to donate to, it simply
looks at the blocking_lock (the lock that is causing the thread to block),
it then can see which thread it needs to donate to by the holder field in
the lock struct. When the receiving thread gets this new priority, it can
apply the same principles to track down the thread it needs to pass on the
donation to if need be.

                                        +==============================+
                                        |           thread 1           |
                                        +------------------------------+
                                        | ...                          |
                                        | lock *blocking_lock; -------------+
                                  +------ int priority = high;         |    |
                                  |     | ...                          |    |
      +========================+  |     +==============================+    |
 +--> |    donated_priority    |  |                                         |
 |    +------------------------+  |                                         |
 |    | int priority = high; <----+           +========================+    |
 |    | lock *blocking_lock; ---------------> |         lock 1         | <--+
 |    | ...                    |              +------------------------+
 |    +========================+              | ...                    |
 |                                            | thread *holder; ------------+
 |                                            | ...                    |    |
 |                                            +========================+    |
 |                                                                          |
 |                                                                          |
 |                                      +==============================+    |
 |                                      |           thread 2           | <--+
 |                                      +------------------------------+
 |                                      | ...                          |
 +--------------(list of)---------------- list donated_priorities;     |
                                        | lock *blocking_lock; -------------+
                                        | int self_set_priority = med; |    |
                                   +----- int priority = high;         |    |
                                   |    | ...                          |    |
      +========================+   |    +==============================+    |
 +--> |    donated_priority    |   |                                        |
 |    +------------------------+   |                                        |
 |    | int priority = high; <-----+          +========================+    |
 |    | lock *blocking_lock; ---------------> |         lock 2         | <--+
 |    | ...                    |              +------------------------+
 |    +========================+              | ...                    |
 |                                            | thread *holder; ------------+
 |                                            | ...                    |    |
 |                                            +========================+    |
 |                                                                          |
 |                                                                          |
 |                                      +==============================+    |
 |                                      |           thread 3           | <--+
 |                                      +------------------------------+
 |                                      | ...                          |
 +--------------(list of)---------------- list donated_priorities;     |
                                        | int self_set_priority = low; |
                                        | int priority = high;         |
                                        | ...                          |
                                        +==============================+



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Within both semaphores and condition variables, the waiting thread with the
highest priority is simply found from the list each time (using the
has_lower_priority() function). For conditions, this involved adding a
pointer to the thread in each semaphore_elem, in order to find the correct
priority.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

First, the lock will try to be acquired with sema_try_down(), as not
to immediately block if it fails. When sema_try_down() returns false, the
blocking_lock field of the current thread is set to a pointer of the
lock trying to be acquired. The procedure thread_donate_priority() is then
called, with the current thread as its argument.

In thread_donate_priority(), the procedure will immediately return if 
there is no lock blocking the thread (base case of recursive call). The 
thread recieving donation is then found as the blocking_lock's holder.
The next task is to traverse the donated_priorities list in the recieving
thread, if a priority has been donated for the same lock and it is smaller
than the current thread's priority, then the priority is set to that of
the current thread. If the priority is greater than the current thread then
the function returns, as there is no point donating a lower priority for the
same lock.

If no priority has been donated for this lock, then a new donated_priority
struct is malloced and inserted into the ordered list of donated priorities
for the recieving thread. The list is ordered by priority and is kept
in descending order.

thread_choose_priority is then called on the receiving thread. This function 
basically compares the values of the priority set by the thread, and the head
of the donated priorities list, and then sets the priority field to whichever 
is highest.

thread_donate_priority() is now called again on the receiving thread, which
gives it the chance to donate if nested donation is required. After this 
the function exits.

Finally, sema_down() is called and the thread waits for the lock to be
released.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

The holder field of the lock is set to NULL, and thread_remove_priority()
is called with the current thread and lock as parameters. This simply 
removes the donated_priority struct associated with the lock from the
thread's donated_priorities list, and free's the memory.
thread_choose_priority() is then called to update the thread's priority,
sema_up() is finally called to release the lock.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

It is possible that, implemented differently, there would be a race condition
between a thread setting its own priority, and another thread trying to set
the same priority (eg. through priority donation). In this case, one of the
values could be overwritten before it is stored.

Our implementation avoids this by having the two variables stored seperately.
That is, when another thread tries to donate priority, this is stored in an
ordered list, and only then is it used to 'thread_choose_priority()'. However,
when a thread sets its own priority, this is stored in a seperate variable,
self_set_priority. This ensures that the two never interfere.

A lock could have been used, but would still require extra work in order to
store a thread's donated priorities.


---RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered storing the list of threads waiting on the synchronisation
primitives in order of priority. However, this would have meant adding
more code and storing more data when the priority of a thread changes.

As far as priority donation is concerned, it soon became clear that a
list of donated priorities would be needed to handle multiple donation,
with a seperate variable to allow the thread's directly set priority to
be preserved.

An option considered was that the priority_donation structs would contain
pointers to the thread's that the priorities should be stored in a hash table
opposed to a list, to allow values to be removed in constant time. But the 
benefit of using an ordered list instead was that the highest priority could
be accessed from the head of the list, an ordered hashtable would have to
be written to accomplish this. It was then decided that given the small number
of priorities likely to be donated, this approach would be slower in practice
than the ordered list, even if it had better time complexity.

It was also discussed that the priority field should be removed from the
thread struct, and there should be a get_priority() function to return
either the set priority, or the head of the donated priorities. But it was
decided that the priority of a thread was going to be required to be
calculated too often with this method, and it would be better to call a
method to set the field, which became thread_choose_priority().

Additionally, a semaphore had to be used instead of a lock to control access
to priority_donations (priority_sema). This is because the lock would have 
had to be released indirectly from lock_release(), resulting in an infinite 
loop.


              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int nice;                          /* Niceness. */
    int recent_cpu;                    /* Measure of how much CPU time
                                          a thread has received recently. */

Added to thread.c:

    static int ready_count;     /* Number of processes on the ready list. */
    static int load_avg;        /* System load average. In fixed-point
                                   arithmetic. */


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer         recent_cpu         priority   thread
ticks     A       B       C     A   B   C   to run
-----   -----   -----   -----  --  --  --   ------
 0      0.091   1.091   2.091  63  61  59      A
 4      0.091   1.091   2.091  62  60  58      A
 8      0.091   1.091   2.091  62  60  58      A
12      0.091   1.091   2.091  62  60  58      A
16      0.091   1.091   2.091  62  60  58      A
20      0.091   1.091   2.091  62  60  58      A
24      0.091   1.091   2.091  62  60  58      A
28      0.091   1.091   2.091  62  60  58      A
32      0.091   1.091   2.091  62  60  58      A
36      0.091   1.091   2.091  62  60  58      A


>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?

The specification does not mention the order in which load_avg and threads'
recent_cpu and priority values should be calculated. Also, load_avg
and recent_cpu are real numbers but their precision is not given

We resolved the first issue based on the dependence of these variables so
that changes propagate quickly from a source variable to a dependent variable.
First, we increment current thread's recent_cpu. Then we calculate load_avg
as it depends only on the number of ready threads and itself. After this
we calculate the new recent_cpu (it depends on load_avg) and the new priority
(depends on recent_cpu). Obviously not all of these calculations are made
with each timer tick as given by the specification. But this is the order
in which they happen.

For the real numbers we implemented a fixed-point arithmetic with 14
fractional bits. This allows for fairly reasonably accurate representation
of real numbers and while still being able to contain really big numbers.
There is no need for these (big numbers) anyway as load_avg uses only
the number of ready threads for its calculation (which should not exceed
a few thousands in the worst case for something like PintOS). Also,
recent_cpu's value stays quite small thanks to relatively small value
of load_avg and nice.


>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

//TODO: I don't bloody know. Will be slow? 


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the task, how might you choose to
>> refine or improve your design?

The design is quite simple and easy to understand as it is now. The most
changes are in thread_tick (well some auxiliary functions are called from
there) and a few other functions were modified a little. Otherwise completely
new functions were added and a lot of the already existing infrastructure
for the basic scheduler is reused.

A little disadvantage could be the occasional presence of if statements
checking for the mlfqs flag which indicates whether the basic or advanced
scheduler is used.

With extra time and some refactoring the code in thread.c could be modified
so that there are a few static function pointers initialised at the start
depending on which scheduler is used. Then functions represented by these
function pointers could be called without the knowledge of the active
scheduler. The two schedulers could be factored out into separate files
while still referencing some code they have in common. It would be something
like a base abstract class and two subclasses in OOP. The usefulness of
such a solution would be bigger though especially if there was more
scheduler-specific code.


>> C6: The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?

Fixed-point arithmetic was implemented as a set of macros. It is not
used in too many places and since all that is required are just simple
calculations it is sufficient to just have the preprocessor replace
the macro uses with mathematical expressions.

Using functions is not needed here at all. It could improve code readability
a little but it would introduce unnecessary costly function calls.


               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining tasks?

>> Any other comments?
